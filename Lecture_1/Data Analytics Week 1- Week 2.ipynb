{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e75a057-f8a5-4f96-8e0b-4ca5a51806bd",
   "metadata": {},
   "source": [
    "$\\textbf{Difference Between Data Science and Data Analytics}$\n",
    "\n",
    "1. $\\textbf{Objective and Scope:}$\n",
    "\n",
    "Data science:\n",
    "\n",
    "    - broader in scope.\n",
    "    - Involves creating new ways of modeling and understanding raw data.\n",
    "    - Focus on designing and constructing new processes for data modeling.\n",
    "    - Rooted from computational statistics\n",
    "\n",
    "Data analytics:\n",
    "  \n",
    "    - Focused more on processing and performing statistical analysis on existing datasets.\n",
    "    - Data analysts often use established processes to uncover useful information and to help organizations make informed decisions.\n",
    "    - Rooted form inferential statistics\n",
    "    \n",
    "\n",
    "2. $\\textbf{Tools and Techniques:}$\n",
    "\n",
    "Data science:\n",
    "\n",
    "    - Capable of performing mathematical and statistical modelling for non-tractable probability distribution (common in high dimensional data).\n",
    "    - Use a wide array of advanced analytical techniques and algorithms, including machine learning, predictive modeling, data mining, and high dimensional data.\n",
    "      \n",
    "\n",
    "Data analytics:\n",
    "\n",
    "    - Focused more on common and well established probability distributions.\n",
    "    - Primarily focus on parsing through existing data and interpreting it.\n",
    "    - Use statistical tools and techniques to analyze, visualize, and present data.\n",
    "\n",
    "3. $\\textbf{Skill Set and Background:}$\n",
    "\n",
    "Data Science:\n",
    "\n",
    "    - Typically requires a stronger background in mathematics, computer science and statistics.\n",
    "    - Needs to be skilled in coding to translate statistical models into working algorithms.\n",
    "\n",
    "Data Analytics:\n",
    "\n",
    "    - Requires stronger skills in mathematics and statistics then in compuyter science.\n",
    "    - Data analysts need to be adept at data cleaning, data visualization, and using statistical methods to analyze data.\n",
    "\n",
    "4. $\\textbf{End Goals:}$\n",
    "\n",
    "Data Science: \n",
    "\n",
    "    - The end goal is often to create new ways of modeling data. \n",
    "    - It's more about building new algorithms and predictive models to predict future events or to discover patterns that were previously unknown.\n",
    "\n",
    "Data Analytics: \n",
    "\n",
    "    - The focus is on solving problems related to the current data. \n",
    "    - Analysts work to uncover trends and insights that are used for immediate decision-making.\n",
    "\n",
    "5. $\\textbf{Nature of Work:}$\n",
    "\n",
    "Data Science: \n",
    "\n",
    "    - More exploratory and experimental (developing new or novel methods). \n",
    "    - Data scientists work on larger sets of data to discover what questions can be asked and answered (You have a model, to fit to an unknown business problem).\n",
    "\n",
    "Data Analytics: \n",
    "\n",
    "    - Focused on answering specific questions and helping to solve specific problems. \n",
    "    - It's generally more straightforward and less experimental than data science (You are given a business problem you need to fit a model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eb5455-dd1d-450a-b423-ef7f38a9c793",
   "metadata": {},
   "source": [
    "$\\textbf{Probability Distribution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74dab0-9cb2-44c0-8b7a-02e0117cb303",
   "metadata": {},
   "source": [
    "1. A random experiment: You have the same experiment, the same method but you always get a different result.\n",
    "2. A random event: generated by a random process, that is the outcome maybe the desired result or not.\n",
    "3. A random variable: A function that assigns a value to each outcome example head=1, tails=0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd71304-3c1e-46c8-b9a3-757019562280",
   "metadata": {},
   "source": [
    "$\\textbf{Discrete Distributions}$\n",
    "- Models a countably finite or countably infinite distinct values.\n",
    "- Let $Y$ be a discrete random variable with a probability function $f(y)$. Then the expected value of $Y$, $E(Y)$ is defined as:\n",
    "\\begin{equation}\n",
    "E(Y) = \\Sigma_{y}yf(y)\n",
    "\\end{equation}\n",
    "\n",
    "Example:\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "\\begin{array}{c|c}\n",
    "y & p(y) \\\\\n",
    "0 & \\frac{1}{4} \\\\\n",
    "1 & \\frac{1}{2} \\\\\n",
    "2 & \\frac{1}{4} \\\\\n",
    "\\end{array}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "E(Y) = \\Sigma_{y}yf(y) = (0)(\\frac{1}{4}) + (1) (\\frac{1}{2}) + (2) (\\frac{1}{4}) = 1\n",
    "\\end{equation}\n",
    "\n",
    "- The variance of a discrete function\n",
    "\\begin{gather}\n",
    "V(Y) = E[(Y-E[Y])^{2}] = E[(Y-E[Y])(Y-E[Y])] = E[(Y)^2 -2(Y)(E[Y])+E[Y]^{2}]\n",
    "\\\\\n",
    "= E[Y^{2}] - 2(E[Y])(E[Y])+E[Y]^{2} = E[Y^{2}] - E[Y]^{2}\n",
    "\\end{gather}\n",
    "\n",
    "\\begin{gather}\n",
    "V(Y) = E[(Y - E[Y])^2] = \\Sigma_{y}(y-E[y])^2f(y) \n",
    "\\\\\n",
    "= (0-1)^2(\\frac{1}{4}) + (1-1)^2 (\\frac{1}{2}) + (2-1)^2 (\\frac{1}{4}) \n",
    "\\\\\n",
    "= (-1)^2(\\frac{1}{4}) + (0)^2 (\\frac{1}{2}) + (1)^2 (\\frac{1}{4}) \n",
    "\\\\\n",
    "= (1)(\\frac{1}{4}) + (0) (\\frac{1}{2}) + (1) (\\frac{1}{4}) \n",
    "\\\\\n",
    "= (1)(\\frac{1}{4}) + (1) (\\frac{1}{4}) = \\frac{1}{8}\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46818dfb-4294-4ef4-8438-5e1e9b50813c",
   "metadata": {},
   "source": [
    "$\\textbf{Binomial Probability Distribution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60030aea-940a-45ad-9095-f6e32fddae91",
   "metadata": {},
   "source": [
    "A Binomial process has the following properties:\n",
    "\n",
    "1. The process consists of a fixed number of identical trials, $n$.\n",
    "\n",
    "2. Each trial results in either a success, $S$, or a failure, $F$.\n",
    "\n",
    "3. The probability of a sucess on a single trial is $p$ which remains the same from trial to trial.\n",
    "\n",
    "4. The probability of a failure is equal to $q=1-p$.\n",
    "\n",
    "5. Trials are independent.\n",
    "\n",
    "6. The random variable of interest is $Y$, representing the number of successes observed during the n trials.\n",
    "\n",
    "7. $p(y) = \\begin{pmatrix}n \\\\y \\end{pmatrix}p^y(1-p)^{n-y}$\n",
    "\n",
    "8. The mean value $E[Y] = np$ and the variance is $Var[Y] = npq$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a50829-3c86-4703-bca7-f59b4c6c1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.graph_objects as go\n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 10\n",
    "p = 0.1\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "# plotting the graph  \n",
    "fig = go.Figure([go.Bar(x=r_values, y=dist)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0919124d-ea8b-4cd4-a362-0fcf15b5bf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "import plotly.graph_objects as go\n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 10\n",
    "p = 0.5\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "fig = go.Figure([go.Bar(x=r_values, y=dist)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de42be75-7e99-4fc2-be5c-ca53c928336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "import plotly.graph_objects as go\n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 10\n",
    "p = 0.9\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ] \n",
    "# plotting the graph  \n",
    "fig = go.Figure([go.Bar(x=r_values, y=dist)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ef825-b72b-4b51-a41d-cfd725918c64",
   "metadata": {},
   "source": [
    "${Real World Application}$\n",
    "\n",
    "An eletrcial companyt hired you as a data scientist, the company was wondering if there current pilot batch of electronic parts is good for public consumption. Currently a lot of 5,000 electrical fuses is assumed to contain 5% defectives. If a sample of 5 fuses is tested, find the probability of observing at least one is defective. Is 5% too high?\n",
    "\n",
    "Given:\n",
    "n = 5\n",
    "Success = 0 (by the condition that at least 1 is defective).\n",
    "\n",
    "$P(failed) = 1 - success = 1 - working \\ condition$\n",
    "\n",
    "$p(y) = 1-p(0) = 1-\\begin{pmatrix}5 \\\\ 0 \\end{pmatrix} p^0(1-p)^5 = 1 - (\\frac{5!}{0!(5-0)!})(0.05)^0(1-0.05)^{5-0} = 1-(0.95)^5 = 0.226$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b0353-2551-482c-a687-31a5b109a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom \n",
    "import plotly.graph_objects as go\n",
    "# setting the values \n",
    "# of n and p \n",
    "n = 5\n",
    "p = 0.05\n",
    "# defining list of r values \n",
    "r_values = list(range(n + 1)) \n",
    "# list of pmf values \n",
    "dist = [binom.pmf(r, n, p) for r in r_values ]\n",
    "\n",
    "# plotting the graph  \n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(x=r_values, y=dist, name = \"Prob.\")\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079506e-55af-467a-9988-d96570ca8447",
   "metadata": {},
   "source": [
    "$\\textbf{Geometric Probability Distribution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07e864-7ece-48a9-83e4-e0a85705c58b",
   "metadata": {},
   "source": [
    "- Is similar to the Binomial distribution except it measures the of the probabaility of the 1st success.\n",
    "- $p(y) = q^{y-1}p$\n",
    "- Mean value, $E[Y] = \\frac{1}{p}$\n",
    "- Variance, $Var[Y] = \\frac{1-p}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89e480-7223-4084-83ea-9a47af09b47e",
   "metadata": {},
   "source": [
    "$\\textbf{Example:}$\n",
    "Suppose that the probability of an engine malfunction during any one-hour period is $p = 0.02$. Find the probability that a given engine will survive two hours.\n",
    "\n",
    "$P(survive \\ two \\ hours) = 1 - \\Sigma_{y=1}^2p(y) = 1 - [(0.98)^{1-1}(0.02)+0.98)^{2-1}(0.02)]\n",
    " = 1-[(0.02)+(0.98)(0.02)] = 0.9604$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225875c2-6c1c-4ee1-98f5-6013630a3c8f",
   "metadata": {},
   "source": [
    "$\\textbf{Negative Binomial Probability Distribution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63f449-25dc-4a26-a331-6cf90317c8ba",
   "metadata": {},
   "source": [
    "- While the geometric probability distribution handles the case where we are intereste in knowing the number of trials of the first success, the negative binomial is focused on knowing the number of trial on the 2nd, 3rd, 4th, 5th,etc. success.\n",
    "- Given $y-1$ trials with $r-1$ success, where $y$ is equal to the number of trial on which the $r^{th}$ success occurs ($r = 2,3,4,5,...$)\n",
    "- $p(y) = \\begin{pmatrix}y-1 \\\\ r-1 \\end{pmatrix} p^rq^{y-r}$\n",
    "- The expected value is $E[Y] = \\frac{r}{p}$\n",
    "- The variance is $V(Y)=\\frac{r(1-p)}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02d972-bad0-48b3-8f90-e7901d714af1",
   "metadata": {},
   "source": [
    "$\\textbf{Poisson Probability distribution}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d6bd0-7530-4e01-a5ad-24d023f41343",
   "metadata": {},
   "source": [
    "- Modelling rare events that occur in space, time, and volume, or any other dimension.\n",
    "- The rare events is represented by the random variable $Y$.\n",
    "- A paramter $\\lambda$ is the average value of $Y$.\n",
    "- This is indutrially used to models any forms of accidents (motor, industrial, etc.)\n",
    "- $p(y) = \\frac{\\lambda^y}{y!}e^{-\\lambda} \\ \\forall \\lambda>0 \\, \\  and \\ y\\geq0$\n",
    "- $E[Y]=V[Y]=\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a0f75f-c145-4af3-bff0-3d43e4d7bfc1",
   "metadata": {},
   "source": [
    "$\\textbf{Example:}$ A certain type of tree has seedlings randomly dispersed in a large area, with the mean density of seedlings being approximately five seed per square yard. If a forester randomly locates ten 1-square yard sampling regions in the area, find the probability that none of the regions will contain seedlings \n",
    "\n",
    "Solution:\n",
    "\n",
    "- $\\lambda$ = 5\n",
    "- $P(Y=0)=\\frac{\\lambda^y}{y!}e^{-\\lambda} = \\frac{5^0}{0!}e^{-5} = 0.006738 = 0.6738\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27864e11-2dc1-47a6-a0f5-3219b1c83097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "x = np.arange(0, 10, 0.5)\n",
    "y = poisson.pmf(x, mu=5)\n",
    "fig = go.Figure([go.Bar(x=x, y=y)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc305337-6dce-4ccd-a555-96368299f81c",
   "metadata": {},
   "source": [
    "$\\textbf{Continuous Probability Function}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552b6ab-2fd1-43aa-853a-ea317068ec67",
   "metadata": {},
   "source": [
    "$\\textbf{Review of Differential Calculus}$\n",
    "\n",
    "1. $\\frac{d(a)}{dx} = d(a) = 0$\n",
    "\n",
    "2. $\\frac{d(x^n)}{dx} = d(x^n) = n x^{n-1}$\n",
    "\n",
    "3. $\\frac{d(a \\cdotp x^n)}{dx} = a \\cdotp d(x^n) = a \\cdotp n x^{n-1}$\n",
    "\n",
    "Let $U$ and $V$ be functions of $x$ s.t. $U \\neq V$.\n",
    "\n",
    "1. $\\frac{d(U)}{dx} = d(U)$\n",
    "\n",
    "2. $\\frac{d(a \\cdotp U)}{dx} = a \\cdotp d(U)$\n",
    "\n",
    "3. $\\frac{d(U + V)}{dx} = d(U + V) = d(U) + d(V)$\n",
    "\n",
    "4. $\\frac{d(U \\cdotp V)}{dx} = d(U \\cdotp V) = U \\cdotp d(V) + V \\cdotp d(U)$\n",
    "\n",
    "5. $\\frac{d(\\frac{U}{V})}{dx} = d(\\frac{U}{V}) = \\frac{V \\cdotp d(U) - U \\cdotp d(V)}{V^2}$\n",
    "\n",
    "6. $\\frac{d(U^n)}{dx} = d(U^n) = n \\cdotp U^{n-1} d(U)$\n",
    "\n",
    "7. $\\frac{d(e^{U})}{dx} = d(e^{U}) = e^U d(U)$\n",
    "\n",
    "8. $\\frac{d(a^{U})}{dx} = d(a^{U}) = \\ln(a) \\cdotp a^U \\cdotp d(U)$\n",
    "\n",
    "9. $\\frac{d(\\ln{U})}{dx} = d(\\ln{U}) = \\frac{1}{U} d(U)$\n",
    "\n",
    "10. $\\frac{d(\\log_{a} U)}{dx} = d(d(\\log_{a} U)) = \\log_{a}(e) \\cdotp \\frac{1}{U} \\cdotp d(U)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0ab65f-ee4b-4fc0-a077-479c96f26e21",
   "metadata": {},
   "source": [
    "$\\textbf{Review of Integral Calculus}$\n",
    "\n",
    "https://www.physics.umd.edu/hep/drew/IntegralTable.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654e8fda-366a-4571-ac49-4ce99312cbc8",
   "metadata": {},
   "source": [
    "$\\textbf{Uniform Distribution}$\n",
    "\n",
    "- If $\\theta_1 < \\theta_2$, a random variable, $Y$, is said to have a continuous uniform probability distribution on the interval $(\\theta_1, \\theta_2) \\iff$ the density of $Y$ if\n",
    "\n",
    "\\begin{gather}\n",
    "f(y) = \\begin{cases}\n",
    "      \\frac{1}{\\theta_2 - \\theta_1}, & \\text{if}\\ \\theta_1 \\leq y \\leq \\theta_2 \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{gather}\n",
    "\n",
    "- $E(Y) = \\frac{\\theta_1 - \\theta_2}{2}$\n",
    "\n",
    "- $V(Y) = \\frac{(\\theta_1 - \\theta_2)^2}{2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aee563-0fa1-4f4f-b4bb-aece298c9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#creating an array of values between\n",
    "#-3 to 8 with a difference of 0.1\n",
    "x = np.arange(-3, 8, 0.1)\n",
    "   \n",
    "y = uniform.pdf(x, 0, 5)\n",
    "\n",
    "fig = go.Figure([go.Bar(x=x, y=y)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de57986-9398-47b3-bf49-74e5384a3329",
   "metadata": {},
   "source": [
    "$\\textbf{Gaussian (Normal) Distribution}$\n",
    "\n",
    "- The most common continuous probability distribution.\n",
    "\n",
    "- Known for its bell shaped curve.\n",
    "\n",
    "- A random variable $Y$ is normally distributed $\\iff \\ for \\  \\sigma>0, \\ and \\ -\\infty< \\mu < \\infty$:\n",
    "\n",
    "\\begin{gather}\n",
    "f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}, \\ \\forall \\ -\\infty < y < \\infty\n",
    "\\end{gather}\n",
    "\n",
    "- $E[Y] = \\mu$, $V[Y] = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe346d5",
   "metadata": {},
   "source": [
    "$\\textbf{Deriving the Mean of a Gaussian Distribution by Maximum Likelihood Estimation}$\n",
    "\n",
    "- Given a i.i.d R.V. $Y$ s.t. $Y = {y_1, y_2, ...., y_n}$\n",
    "\n",
    "\\begin{gather}\n",
    "f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}, \\forall -\\infty < y < \\infty\n",
    "\\\\\n",
    "\\\\\n",
    "\\Pi_i^n (f(y_i)) = \\Pi_i^n \\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}} e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}} \\end{pmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "= \\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}^n \\begin{pmatrix}e^{-\\frac{(y_i-\\mu)^2}{2\\sigma^2}}\\end{pmatrix}^n\n",
    "\\\\\n",
    "\\\\\n",
    "= \\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}^n \\begin{pmatrix}e^{-\\Sigma_i^n \\frac{(y_i-\\mu)^2}{2\\sigma^2}}\\end{pmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "\\ln{\\Pi_i^n (f(y_i))} = \\ln \\begin{bmatrix}{\\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}^n \\begin{pmatrix}e^{-\\Sigma_i^n \\frac{(y_i-\\mu)^2}{2\\sigma^2}}\\end{pmatrix}}\\end{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "= n \\ln{\\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}} -\\Sigma_i^n \\frac{(y_i-\\mu)^2}{2\\sigma^2}\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{d(\\ln{\\Pi_i^n (f(y_i))})}{y} = \\frac{d}{dy} \\begin{bmatrix} n \\ln{\\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}} -\\Sigma_i^n \\frac{(y_i-\\mu)^2}{2\\sigma^2}\\end{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "= \\frac{d}{dy} n \\ln{\\begin{pmatrix}\\frac{1}{\\sigma \\sqrt{2 \\pi}}\\end{pmatrix}} - \\frac{d}{dy} \\Sigma_i^n \\frac{( y_i- \\mu)^2}{2\\sigma^2}\n",
    "\\\\\n",
    "\\\\\n",
    "= 0 - \\Sigma_i^n \\frac{d}{dy} \\frac{( y_i- \\mu)^2}{2\\sigma^2}\n",
    "\\\\\n",
    "\\\\\n",
    "= - \\frac{1}{2\\sigma^2} \\Sigma_i^n \\frac{d}{dy} (y_i- \\mu)^2\n",
    "\\\\\n",
    "\\\\\n",
    "= - \\frac{1}{2\\sigma^2} \\Sigma_i^n 2 (y_i- \\mu) \\frac{\\partial(y_i- \\mu)}{\\partial(y)}\n",
    "\\\\\n",
    "\\\\\n",
    "= - \\frac{1}{2\\sigma^2} \\Sigma_i^n 2 (y_i- \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "= - \\frac{2}{2\\sigma^2}  (\\Sigma_i^n y_i- \\Sigma_i^n \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "= - \\frac{1}{\\sigma^2}  (\\Sigma_i^n y_i- n \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{d(\\ln{\\Pi_i^n (f(y_i))})}{y} = 0 = - \\frac{1}{\\sigma^2}  (\\Sigma_i^n y_i- n \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "0 = - \\frac{1}{\\sigma^2}  (\\Sigma_i^n y_i- n \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "0 = (\\Sigma_i^n y_i- n \\mu)\n",
    "\\\\\n",
    "\\\\\n",
    "- \\Sigma_i^n y_i = - n \\mu\n",
    "\\\\\n",
    "\\\\\n",
    "\\frac{\\Sigma_i^n y_i}{n} = \\mu\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc210b75-d231-4cf3-a5a8-9d4e9211c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#creating an array of values between\n",
    "#-3 to 8 with a difference of 0.1\n",
    "x = np.arange(-3, 3.5, 0.1)\n",
    "   \n",
    "y = norm.pdf(x, 0, 1)\n",
    "\n",
    "fig = go.Figure([go.Bar(x=x, y=y)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdb6dfd-2198-4240-a76b-b62745a8284b",
   "metadata": {},
   "source": [
    "$\\textbf{Gamma Distribution}$\n",
    "\n",
    "- When the random variable $Y$ is always positive and always skewed to the right.\n",
    "\n",
    "- Most of the area of the PDF is located near the origin, and the PDF drops gradually as y increases.\n",
    "\n",
    "- A random variable $Y$ has a gamma distributions with parameters $\\alpha>0$ and $\\beta>0$ $\\iff$\n",
    "\n",
    "\\begin{gather}\n",
    "f(y) = \\begin{cases}\n",
    "      \\frac{y^{\\alpha-1}e^{\\frac{-y}{\\beta}}}{\\beta^{\\alpha} \\Gamma(\\alpha)}, & \\text{if}\\ 0\\leq y < \\infty \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{gather}\n",
    "\n",
    "If $\\alpha \\in \\mathbb{R^+} >0$:\n",
    "\n",
    "\\begin{gather}\n",
    "\\Gamma(\\alpha) = \\int_0^\\infty y^{\\alpha-1}e^{-y} dy\n",
    "\\end{gather}\n",
    "\n",
    "If $\\alpha \\in \\mathbb{Z^+} >0$:\n",
    "\n",
    "\\begin{gather}\n",
    "\\Gamma(\\alpha) = (\\alpha-1)!\n",
    "\\end{gather}\n",
    "\n",
    "- $E[Y] = \\alpha \\beta$\n",
    "\n",
    "- $V[Y] = \\alpha \\beta^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53529030-9ef5-430a-994f-59015c7c6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#creating an array of values between\n",
    "#-3 to 8 with a difference of 0.1\n",
    "x = np.arange(0.1, 10, 0.1)\n",
    "   \n",
    "y = gamma.pdf(x, 3, 0.1)\n",
    "\n",
    "fig = go.Figure([go.Bar(x=x, y=y)])\n",
    "fig.update_layout(height = 500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8296f9-20f3-4e58-99ea-94c0c5707a03",
   "metadata": {},
   "source": [
    "$\\textbf{Exponential Distribution}$\n",
    "\n",
    "- For a Gamma distribution with $\\alpha = 1$.\n",
    "\n",
    "\\begin{gather}\n",
    "f(y) = \\begin{cases}\n",
    "      \\frac{e^{\\frac{-y}{\\beta}}}{\\beta}, & \\text{if}\\ 0\\leq y < \\infty \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{gather}\n",
    "\n",
    "- $E[Y] = \\beta$\n",
    "\n",
    "- $V[Y] = \\beta^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964d4eb-fce7-4dfa-9dce-18019135d102",
   "metadata": {},
   "source": [
    "$\\textbf{Beta Distribution}$\n",
    "\n",
    "- For random variables $Y$ with limits $0 \\leq y \\leq 1$.\n",
    "\n",
    "- Used to model proportions.\n",
    "\n",
    "- A random variable $Y$ has a beta distribution with parameters $\\alpha > 0$ and $\\beta >0$ $\\iff$\n",
    "\\begin{gather}\n",
    "f(y) = \\begin{cases}\n",
    "      \\frac{y^{\\alpha-1}(1-y)^{\\beta-1}}{\\beta eta(\\alpha, \\beta)}, & \\text{if}\\ 0\\leq y < \\infty \\\\\n",
    "      0, & \\text{otherwise}\n",
    "    \\end{cases}\n",
    "\\end{gather}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{gather}\n",
    "\\beta eta(\\alpha, \\beta) = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}\n",
    "\\end{gather}\n",
    "\n",
    "- $E[Y] = \\frac{\\alpha}{\\alpha + \\beta}$\n",
    "\n",
    "- $E[Y] = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta +1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a307b2-ede7-46c9-a481-2c1d697308b1",
   "metadata": {},
   "source": [
    "$\\textbf{Correlation}$\n",
    "\n",
    "- Given two i.i.d random variables $x$ and $y$.\n",
    "\n",
    "\\begin{gather}\n",
    "r = \\frac{\\Sigma_i^n (x_i - E[X])(y_i - E[Y])}{\\sqrt{\\Sigma_i^n (x_i - E[X])^2 (y_i - E[Y])^2}}\n",
    "\\end{gather}\n",
    "\n",
    "- The degree of association between two variables.\n",
    " \n",
    "- The correlation coefficient is measured on a scale that varies from + 1 through 0 to – 1. \n",
    "\n",
    "- Complete absence of correlation is represented by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52a2e6e-f1b5-49dd-b571-873580aa2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import pandas as pd\n",
    "\n",
    "# Load the iris dataset from sklearn\n",
    "wine = load_wine()\n",
    "\n",
    "# Convert the iris dataset to a pandas dataframe\n",
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# Add the target variable to the dataframe\n",
    "#df['target'] = iris.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e53c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Correlation\n",
    "df_corr = df.corr().round(1)  \n",
    "# Mask to matrix\n",
    "mask = np.zeros_like(df_corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Viz\n",
    "df_corr_viz = df_corr.mask(mask).dropna(how='all').dropna('columns', how='all')\n",
    "fig = px.imshow(df_corr_viz, text_auto=True)\n",
    "fig.update_layout(height = 900, width=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf79328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in df.columns:\n",
    "    fig.add_trace(go.Box(y=df[str(i)], name=str(i)))\n",
    "fig.update_layout(showlegend=False,height = 700, width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68750fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard = (df-df.mean())/df.std()\n",
    "\n",
    "fig = go.Figure()\n",
    "for i in standard.columns:\n",
    "    fig.add_trace(go.Box(y=standard[str(i)], name=str(i)))\n",
    "fig.update_layout(showlegend=False,height = 700, width=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622e12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Correlation\n",
    "std_corr = standard.corr().round(1)  \n",
    "# Mask to matrix\n",
    "mask = np.zeros_like(std_corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# Viz\n",
    "df_corr_viz = std_corr.mask(mask).dropna(how='all').dropna('columns', how='all')\n",
    "fig = px.imshow(df_corr_viz, text_auto=True)\n",
    "fig.update_layout(height = 900, width=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeda9f2",
   "metadata": {},
   "source": [
    "$\\textbf{Statistical Inference}$\n",
    "\n",
    "- Statistical inference is the process of drawing conclusions about an underlying population based on a sample or subset of the data. \n",
    "\n",
    "- In most cases, it is not practical to obtain all the measurements in a given population. So get a randomly collected sample determine its parameter and infer if this parameter is a true representative of the population.\n",
    "\n",
    "$\\textbf{P-Value}$\n",
    "- It just tells you how likely you’d see the data you observed (or more extreme data) if the null hypothesis was true. It’s a piece of evidence, not a definitive proof.\n",
    "\n",
    "- The null hypothesis is always the \"no effect\".\n",
    "\n",
    "- Example: Suppose you’re conducting a study to determine whether a new drug has an effect on pain relief compared to a placebo. If the new drug has no impact, your test statistic will be close to the one predicted by the null hypothesis (no difference between the drug and placebo groups), and the resulting p-value will be close to 1.\n",
    "\n",
    "- Errors in statistical inference:\n",
    "\n",
    "\\begin{gather}\n",
    "\\begin{bmatrix}\n",
    "Decision & H_0 \\ is \\ True & H_0 \\ is \\ False \\\\\n",
    "Rejected \\ H_0 & Type I Error & Correct \\ Decision \\\\\n",
    "Accpeted \\ H_0 & Correct \\ Decision & Type II Error \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33c9e9",
   "metadata": {},
   "source": [
    "$\\textbf{Different Kinds of Tests}$:\n",
    "\n",
    "1. Paired T-Test:\n",
    "\n",
    "- Used for before and after experiments, example you want to compare the same person before and after a treatment.\n",
    "\n",
    "- Assumption is data should be normally distributed, and samples must be independent of each other.\n",
    "\n",
    "2. Unpaired T-Test:\n",
    "\n",
    "- Used to compared two samples, example you want to compare student performance between synch and asynch classes.\n",
    "\n",
    "- Assumption is data should be normally distributed.\n",
    "\n",
    "3. $\\chi^2$ Test for Goodness of Fit:\n",
    "\n",
    "- Tests if the observed and the actual distributions are the same.\n",
    "\n",
    "- Assumption that data must be categorical with at least 5 categories, and sampled must be independent of each other.\n",
    "\n",
    "4. $\\chi^2$ Test for Homogeniety:\n",
    "\n",
    "- Used to test a single categorical variable from two samples.\n",
    "\n",
    "- Assumption that data must be categorical and sampled must be independent of each other.\n",
    "\n",
    "5. $\\chi^2$ Test for Independence:\n",
    "\n",
    "- Used to test two categorical variables from the same samples.\n",
    "\n",
    "- Assumption that data must be categorical.\n",
    "\n",
    "6. ANOVA\n",
    "\n",
    "- Analysis tool used in statistics that splits an observed aggregate variability found inside a data set into two parts: systematic factors and random factors. The systematic factors have a statistical influence on the given data set, while the random factors do not.\n",
    "\n",
    "- Types I, II and III."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e247af-4d47-4578-84b3-cab9c656a8e1",
   "metadata": {},
   "source": [
    "$\\textbf{PROGRAMMING ASSIGNMENT}$\n",
    "---\n",
    "\n",
    "Data: https://archive.ics.uci.edu\n",
    "\n",
    "Instructions: Choose a dataset of your liking and perform the following:\n",
    "\n",
    "1. Create a Correlation Plot\n",
    "\n",
    "2. Check the distribution of each column and determine which probability distiribution it fits.\n",
    "\n",
    "3. Create a summary statistics.\n",
    "\n",
    "4. Perform a hypothesis test (Code from scratch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf166352-01de-4195-ba06-12481e7d0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d244666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "wine = fetch_ucirepo(id=109) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = wine.data.features \n",
    "y = wine.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(wine.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(wine.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a274cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a correlation plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(X.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Plot', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b87cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "for column in X.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    X[column].hist(bins=20, density=True, edgecolor='black')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Density')\n",
    "\n",
    "    dist_names = ['norm', 'exponweib', 'weibull_max', 'pareto']\n",
    "    for dist_name in dist_names:\n",
    "        dist = getattr(stats, dist_name)\n",
    "        param = dist.fit(X[column])\n",
    "        print(f'{dist_name} distribution parameters for {column}: {param}')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80eb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3789c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Hypothesis test for mean alcohol content\n",
    "hypothesized_mean = 10.0\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Calculate the sample mean\n",
    "sample_mean = X['Alcohol'].mean()\n",
    "\n",
    "# Calculate the sample standard deviation\n",
    "sample_std = X['Alcohol'].std()\n",
    "\n",
    "# Calculate the test statistic (z-score or t-score, depending on the sample size)\n",
    "n = len(X['Alcohol'])\n",
    "if n > 30:\n",
    "    test_statistic = (sample_mean - hypothesized_mean) / (sample_std / math.sqrt(n))  # z-score\n",
    "else:\n",
    "    test_statistic = (sample_mean - hypothesized_mean) / (sample_std / math.sqrt(n))  # t-score\n",
    "    test_statistic *= (n - 1) / math.sqrt(n)  # Adjust for small sample size\n",
    "\n",
    "# Calculate the p-value\n",
    "if n > 30:\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(test_statistic)))  # For z-score\n",
    "else:\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(test_statistic), n - 1))  # For t-score\n",
    "\n",
    "# Print the results\n",
    "print(f\"Sample mean: {sample_mean:.2f}\")\n",
    "print(f\"Hypothesized mean: {hypothesized_mean}\")\n",
    "print(f\"Test statistic: {test_statistic:.2f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "# Interpret the results\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The mean alcohol content is significantly different from the hypothesized value.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The mean alcohol content is not significantly different from the hypothesized value.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
