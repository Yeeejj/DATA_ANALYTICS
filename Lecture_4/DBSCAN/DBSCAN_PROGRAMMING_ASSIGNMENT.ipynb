{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN Project  \n",
    "\n",
    "## The Data\n",
    "\n",
    "\n",
    "Source: https://archive.ics.uci.edu/ml/datasets/Wholesale+customers\n",
    "\n",
    "Margarida G. M. S. Cardoso, margarida.cardoso '@' iscte.pt, ISCTE-IUL, Lisbon, Portugal\n",
    "\n",
    "\n",
    "Data Set Information:\n",
    "\n",
    "Provide all relevant information about your data set.\n",
    "\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "    1) FRESH: annual spending (m.u.) on fresh products (Continuous);\n",
    "    2) MILK: annual spending (m.u.) on milk products (Continuous);\n",
    "    3) GROCERY: annual spending (m.u.)on grocery products (Continuous);\n",
    "    4) FROZEN: annual spending (m.u.)on frozen products (Continuous)\n",
    "    5) DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous)\n",
    "    6) DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous);\n",
    "    7) CHANNEL: customers  Channel - Horeca (Hotel/Restaurant/CafÃ©) or Retail channel (Nominal)\n",
    "    8) REGION: customers  Region Lisnon, Oporto or Other (Nominal)\n",
    " \n",
    "\n",
    "Relevant Papers:\n",
    "\n",
    "Cardoso, Margarida G.M.S. (2013). Logical discriminant models â€“ Chapter 8 in Quantitative Modeling in Marketing and Management Edited by Luiz Moutinho and Kun-Huang Huarng. World Scientific. p. 223-253. ISBN 978-9814407717\n",
    "\n",
    "Jean-Patrick Baudry, Margarida Cardoso, Gilles Celeux, Maria JosÃ© Amorim, Ana Sousa Ferreira (2012). Enhancing the selection of a model-based clustering with external qualitative variables. RESEARCH REPORT NÂ° 8124, October 2012, Project-Team SELECT. INRIA Saclay - ÃŽle-de-France, Projet select, UniversitÃ© Paris-Sud 11\n",
    "\n",
    "\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPLETE THE REQUIRED TASKS:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "**TASK: Create a scatterplot showing the relation between MILK and GROCERY spending, colored by Channel column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Use seaborn to create a histogram of MILK spending, colored by Channel. Can you figure out how to use seaborn to \"stack\" the channels, instead of have them overlap?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create an annotated clustermap of the correlations between spending on different cateogires.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a PairPlot of the dataframe, colored by Region.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset into a DataFrame\n",
    "data = \"\"\"Channel,Region,Fresh,Milk,Grocery,Frozen,Detergents_Paper,Delicassen\n",
    "2,3,12669,9656,7561,214,2674,1338\n",
    "2,3,7057,9810,9568,1762,3293,1776\n",
    "...\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(pd.compat.StringIO(data), sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Milk', y='Grocery', hue='Channel', data=df)\n",
    "plt.title('Milk vs Grocery Spending (Colored by Channel)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=df, x='Milk', hue='Channel', multiple='stack')\n",
    "plt.title('Histogram of Milk Spending (Stacked by Channel)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.drop(['Channel', 'Region'], axis=1).corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.clustermap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlations Between Spending Categories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "sns.pairplot(df, hue='Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "**TASK: Since the values of the features are in different orders of magnitude, let's scale the data. Use StandardScaler to scale the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Use DBSCAN and a for loop to create a variety of models testing different epsilon values. Set min_samples equal to 2 times the number of features. During the loop, keep track of and log the percentage of points that are outliers. For reference the solutions notebooks uses the following range of epsilon values for testing:**\n",
    "\n",
    "    np.linspace(0.001,3,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a line plot of the percentage of outlier points versus the epsilon value choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df.drop(['Channel', 'Region'], axis=1))\n",
    "\n",
    "# Set the number of features\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Initialize lists to store outlier percentages and epsilon values\n",
    "outlier_percentages = []\n",
    "epsilon_values = np.linspace(0.001, 3, 50)\n",
    "\n",
    "# Loop over different epsilon values\n",
    "for eps in epsilon_values:\n",
    "    # Create a DBSCAN model\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=2 * n_features)\n",
    "    \n",
    "    # Fit the model\n",
    "    clusters = dbscan.fit_predict(X)\n",
    "    \n",
    "    # Calculate the number of outliers\n",
    "    n_outliers = (clusters == -1).sum()\n",
    "    \n",
    "    # Calculate the percentage of outliers\n",
    "    outlier_percentage = n_outliers / len(X) * 100\n",
    "    outlier_percentages.append(outlier_percentage)\n",
    "\n",
    "# Plot the outlier percentage vs epsilon values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilon_values, outlier_percentages)\n",
    "plt.xlabel('Epsilon Value')\n",
    "plt.ylabel('Percentage of Outliers')\n",
    "plt.title('Outlier Percentage vs Epsilon Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN with Chosen Epsilon\n",
    "\n",
    "**TASK: Based on the plot created in the previous task, retrain a DBSCAN model with a reasonable epsilon value. Note: For reference, the solutions use eps=2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a scatterplot of Milk vs Grocery, colored by the discovered labels of the DBSCAN model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a scatterplot of Milk vs. Detergents Paper colored by the labels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a new column on the original dataframe called \"Labels\" consisting of the DBSCAN labels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Compare the statistical mean of the clusters and outliers for the spending amounts on the categories.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Normalize the dataframe from the previous task using MinMaxScaler so the spending means go from 0-1 and create a heatmap of the values.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create another heatmap similar to the one above, but with the outliers removed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: What spending category were the two clusters mode different in?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Retrain DBSCAN model with chosen epsilon value\n",
    "dbscan = DBSCAN(eps=2, min_samples=2 * n_features)\n",
    "labels = dbscan.fit_predict(X)\n",
    "\n",
    "# Create a scatterplot of Milk vs Grocery, colored by DBSCAN labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['Milk'], df['Grocery'], c=labels)\n",
    "plt.xlabel('Milk')\n",
    "plt.ylabel('Grocery')\n",
    "plt.title('Milk vs Grocery Spending (Colored by DBSCAN Labels)')\n",
    "plt.show()\n",
    "\n",
    "# Create a scatterplot of Milk vs Detergents_Paper, colored by DBSCAN labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['Milk'], df['Detergents_Paper'], c=labels)\n",
    "plt.xlabel('Milk')\n",
    "plt.ylabel('Detergents_Paper')\n",
    "plt.title('Milk vs Detergents_Paper Spending (Colored by DBSCAN Labels)')\n",
    "plt.show()\n",
    "\n",
    "# Add DBSCAN labels to the original dataframe\n",
    "df['Labels'] = labels\n",
    "\n",
    "# Compare the statistical mean of clusters and outliers\n",
    "cluster_means = df.groupby('Labels').mean()\n",
    "print('Cluster Means:\\n', cluster_means)\n",
    "\n",
    "# Normalize the dataframe\n",
    "norm_scaler = MinMaxScaler()\n",
    "norm_df = pd.DataFrame(norm_scaler.fit_transform(df.drop(['Channel', 'Region', 'Labels'], axis=1)), columns=df.drop(['Channel', 'Region', 'Labels'], axis=1).columns)\n",
    "norm_df['Labels'] = df['Labels']\n",
    "\n",
    "# Create a heatmap of normalized values\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(norm_df.groupby('Labels').mean(), annot=True, cmap='coolwarm')\n",
    "plt.title('Normalized Spending Means by Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap without outliers\n",
    "inlier_mask = norm_df['Labels'] != -1\n",
    "inlier_df = norm_df[inlier_mask]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(inlier_df.groupby('Labels').mean(), annot=True, cmap='coolwarm')\n",
    "plt.title('Normalized Spending Means by Cluster (Outliers Removed)')\n",
    "plt.show()\n",
    "\n",
    "# Identify the category with the most significant difference between clusters\n",
    "category_differences = cluster_means.iloc[0] - cluster_means.iloc[1]\n",
    "most_different_category = category_differences.abs().idxmax()\n",
    "print(f'The spending category with the most significant difference between clusters is: {most_different_category}')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
